{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vn5wnnje505e",
    "outputId": "81a6fde7-1c39-484c-8538-c8a28e44d34a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install torch numpy transformers pandas scikit-learn sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYHRvjRO6Pnm",
    "outputId": "0e96fc51-2edb-4cfd-a25c-b296042e7bce"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxzgXDpEj181",
    "outputId": "bb292909-1cef-4d3f-b00e-11db590f01ae"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "text = [\"Good night honey ðŸ˜Š\", \"lmao xd ðŸ˜Š\"]\n",
    "#text = preprocess(text)\n",
    "\n",
    "# Pytorch\n",
    "roberta = AutoModel.from_pretrained(MODEL).to(device)\n",
    "modules = [roberta.embeddings, *roberta.encoder.layer[:10]]  #do przetestowania rÃ³Å¼ne parametry\n",
    "for module in modules:\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "#encoded_input = tokenizer(text, return_tensors='pt', padding=True)\n",
    "#features = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXhmdf8GYito"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"train_dataset.csv\")\n",
    "X = df[\"tweet_content\"].tolist()\n",
    "X = [preprocess(x) for x in X]\n",
    "y = (df[\"sarcasm_label\"] == 'sarcastic').tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLQ00Vvt167U"
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import pad\n",
    "\n",
    "X_encoded = tokenizer(X, return_tensors='pt', padding=True)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeHLYYKLHtOI"
   },
   "outputs": [],
   "source": [
    "X_train, X_cross, y_train, y_cross = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "y_train = torch.Tensor(y_train).type(torch.long)\n",
    "y_cross = torch.Tensor(y_cross).type(torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVEpbnsGnBFr"
   },
   "outputs": [],
   "source": [
    "#dobija do f_score = 0.4 gdy trenujemy roberte\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.roberta = roberta\n",
    "        self.lstm = nn.LSTM(768, 64, 2, bidirectional=True, dropout=0.2)\n",
    "        self.linear1 = nn.Linear(716, 100)\n",
    "        self.linear2 = nn.Linear(100, 20)\n",
    "        self.linear3 = nn.Linear(20, 2)\n",
    "        self.pooling = nn.MaxPool2d((30, 5))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.roberta(x).last_hidden_state\n",
    "        x, _ = self.lstm(x1)\n",
    "        x = torch.cat((x1, x), dim=2)\n",
    "        x = self.pooling(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-ksWbjx1zvR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset_train = TensorDataset(X_train, y_train)  # create your datset\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=40)  # create your dataloader\n",
    "dataset_cross = TensorDataset(X_cross, y_cross)  # create your datset\n",
    "dataloader_cross = DataLoader(dataset_cross, batch_size=40)  # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHvhH7x1smki"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):  #fragment z dokumentacji pytorch\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss :>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= num_batches\n",
    "    print(f\"Avg train loss: {train_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbCbcRH531-o"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    true_positive, true_negative, false_negative, false_positive = 0.0001, 0.0001, 0.0001, 0.0001  #zeby dzielenia przez zero nie bylo\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            y_pred = pred.argmax(1)\n",
    "            correct += (y_pred == y).type(torch.long).sum().item()\n",
    "\n",
    "            true_positive += torch.logical_and(y_pred == y, y == 1).sum().item()\n",
    "            true_negative += torch.logical_and(y_pred == y, y == 0).sum().item()\n",
    "            false_negative += torch.logical_and(y_pred != y, y == 1).sum().item()\n",
    "            false_positive += torch.logical_and(y_pred != y, y == 0).sum().item()\n",
    "\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    specificity = true_negative / (false_positive + true_negative)\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "    g_mean = (recall * specificity) ** (0.5)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    print(\n",
    "        f\"\\n recall: {recall} \\n precision: {precision} \\n specificity: {specificity} \\n f_score: {f_score} \\n g_mean: {g_mean}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5ZkvpljVBoG"
   },
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0MzXjEZ5VLE"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(weight=torch.Tensor([1.0, 1.0])).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JF1mZGWKxYJE",
    "outputId": "d79dd88d-d7a8-40fb-87f3-3c563531cdd6"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    train(dataloader_train, model, loss_fn, optimizer)\n",
    "    test(dataloader_cross, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWXKx3gzwXU9"
   },
   "outputs": [],
   "source": [
    "model_name = \"sarcasm_detection_model\"\n",
    "model_name_pt = f\"{model_name}.pt\"\n",
    "model_name_onnx = f\"{model_name}.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_name_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pytorch_model = Model()\n",
    "pytorch_model.load_state_dict(torch.load(model_name_pt))\n",
    "pytorch_model.eval()\n",
    "dummy_input = torch.zeros(1, 1, 1, 1)  #TODO figure out the dummy input\n",
    "torch.onnx.export(pytorch_model, dummy_input, model_name_onnx, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "inzynierka_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}